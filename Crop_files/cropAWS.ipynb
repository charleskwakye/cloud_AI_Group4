{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\teste\\documents\\3rd year\\cloud ai\\cloud ai github\\cloudai\\venv\\lib\\site-packages (1.3.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in c:\\users\\teste\\documents\\3rd year\\cloud ai\\cloud ai github\\cloudai\\venv\\lib\\site-packages (from scikit-learn) (1.26.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\teste\\documents\\3rd year\\cloud ai\\cloud ai github\\cloudai\\venv\\lib\\site-packages (from scikit-learn) (1.11.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\teste\\documents\\3rd year\\cloud ai\\cloud ai github\\cloudai\\venv\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\teste\\documents\\3rd year\\cloud ai\\cloud ai github\\cloudai\\venv\\lib\\site-packages (from scikit-learn) (3.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "import warnings, requests, zipfile, io\n",
    "warnings.simplefilter('ignore')\n",
    "import pandas as pd\n",
    "from scipy.io import arff\n",
    "\n",
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.image_uris import retrieve\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting Data Ready:\n",
    "I'll Open a CSV file containing the dataset, remove any unnecessary columns, and use LabelEncoder to encode categorical values. To start with the prediction objective.\n",
    "\n",
    "Splitting & Uploading Data:\n",
    "Train_test_split will be used to divide the dataset into training, testing, and validation sets.\n",
    "\n",
    "Then I will transfer these datasets to a bucket on Amazon S3.\n",
    "\n",
    "Setting Up and Teaching the Model:\n",
    "Using SageMaker, I will set up an XGBoost model by specifying its hyperparameters and specifications.\n",
    "Utilising the ready-made training data kept in S3, train the XGBoost model.\n",
    "\n",
    "Model Forecast:\n",
    "Then I will get the test dataset ready for forecasting and submit it to S3.\n",
    "\n",
    "A SageMaker batch transformation process is started to enable the learned model to generate predictions.\n",
    "\n",
    "Then obtain and save the forecast outcomes in a Pandas DataFrame.\n",
    "\n",
    "Measures of Performance:\n",
    "The performance indicators like specificity, sensitivity, ROC curve, confusion matrix, and more will be determined for model evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def plot_roc(test_labels, target_predicted_binary):\n",
    "    TN, FP, FN, TP = confusion_matrix(test_labels, target_predicted_binary).ravel()\n",
    "    # Sensitivity, hit rate, recall, or true positive rate\n",
    "    Sensitivity  = float(TP)/(TP+FN)*100\n",
    "    # Specificity or true negative rate\n",
    "    Specificity  = float(TN)/(TN+FP)*100\n",
    "    # Precision or positive predictive value\n",
    "    Precision = float(TP)/(TP+FP)*100\n",
    "    # Negative predictive value\n",
    "    NPV = float(TN)/(TN+FN)*100\n",
    "    # Fall out or false positive rate\n",
    "    FPR = float(FP)/(FP+TN)*100\n",
    "    # False negative rate\n",
    "    FNR = float(FN)/(TP+FN)*100\n",
    "    # False discovery rate\n",
    "    FDR = float(FP)/(TP+FP)*100\n",
    "    # Overall accuracy\n",
    "    ACC = float(TP+TN)/(TP+FP+FN+TN)*100\n",
    "\n",
    "    print(f\"Sensitivity or TPR: {Sensitivity}%\")    \n",
    "    print(f\"Specificity or TNR: {Specificity}%\") \n",
    "    print(f\"Precision: {Precision}%\")   \n",
    "    print(f\"Negative Predictive Value: {NPV}%\")  \n",
    "    print( f\"False Positive Rate: {FPR}%\") \n",
    "    print(f\"False Negative Rate: {FNR}%\")  \n",
    "    print(f\"False Discovery Rate: {FDR}%\" )\n",
    "    print(f\"Accuracy: {ACC}%\") \n",
    "\n",
    "    test_labels = test.iloc[:,0];\n",
    "    print(\"Validation AUC\", roc_auc_score(test_labels, target_predicted_binary) )\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(test_labels, target_predicted_binary)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % (roc_auc))\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "\n",
    "    # create the axis of thresholds (scores)\n",
    "    ax2 = plt.gca().twinx()\n",
    "    ax2.plot(fpr, thresholds, markeredgecolor='r',linestyle='dashed', color='r')\n",
    "    ax2.set_ylabel('Threshold',color='r')\n",
    "    ax2.set_ylim([thresholds[-1],thresholds[0]])\n",
    "    ax2.set_xlim([fpr[0],fpr[-1]])\n",
    "\n",
    "    print(plt.figure())\n",
    "\n",
    "def plot_confusion_matrix(test_labels, target_predicted):\n",
    "    matrix = confusion_matrix(test_labels, target_predicted)\n",
    "    df_confusion = pd.DataFrame(matrix)\n",
    "    colormap = sns.color_palette(\"BrBG\", 10)\n",
    "    sns.heatmap(df_confusion, annot=True, fmt='.2f', cbar=None, cmap=colormap)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel(\"True Class\")\n",
    "    plt.xlabel(\"Predicted Class\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "df = pd.read_csv('cropfolder/cropStats.csv',delimiter=',')\n",
    "\n",
    "# Dropping the first and last columns\n",
    "df = df.iloc[:, 1:-1]  # Selects all rows, and columns from index 1 to the second-to-last column\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df['states_encoded'] = label_encoder.fit_transform(df['Location'])\n",
    "\n",
    "# Create a new DataFrame with 'states_encoded' as the first column\n",
    "new_order = ['states_encoded'] + [col for col in df if col != 'states_encoded']\n",
    "df = df[new_order]\n",
    "\n",
    "# Drop the original 'Location' column after encoding\n",
    "df = df.drop('Location', axis=1)\n",
    "df\n",
    "\n",
    "# column to be predicted is 2017 column, so that comes first\n",
    "\n",
    "cols = df.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "df = df[cols]\n",
    "df\n",
    "\n",
    "train, test_and_validate = train_test_split(df, test_size=0.2, random_state=42)\n",
    "test, validate = train_test_split(test_and_validate, test_size=0.5, random_state=42)\n",
    "\n",
    "prefix='lab3'\n",
    "\n",
    "train_file='crop_train.csv'\n",
    "test_file='crop_test.csv'\n",
    "validate_file='crop_validate.csv'\n",
    "\n",
    "s3_resource = boto3.Session().resource('s3')\n",
    "def upload_s3_csv(filename, folder, dataframe):\n",
    "    csv_buffer = io.StringIO()\n",
    "    dataframe.to_csv(csv_buffer, header=False, index=False )\n",
    "    s3_resource.Bucket(bucket).Object(os.path.join(prefix, folder, filename)).put(Body=csv_buffer.getvalue())\n",
    "\n",
    "upload_s3_csv(train_file, 'train', train)\n",
    "upload_s3_csv(test_file, 'test', test)\n",
    "upload_s3_csv(validate_file, 'validate', validate)\n",
    "\n",
    "container = retrieve('xgboost',boto3.Session().region_name,'1.0-1')\n",
    "\n",
    "hyperparams = {\n",
    "    \"num_round\": \"100\",\n",
    "    \"eval_metric\": \"rmse\",  # Evaluation metric (Root Mean Squared Error)\n",
    "    \"objective\": \"reg:squarederror\",  # Objective for regression\n",
    "    \"silent\": 1\n",
    "}\n",
    "\n",
    "s3_output_location=\"s3://{}/{}/output/\".format(bucket,prefix)\n",
    "xgb_model=sagemaker.estimator.Estimator(container,\n",
    "                                       sagemaker.get_execution_role(),\n",
    "                                       instance_count=1,\n",
    "                                       instance_type='ml.m5.2xlarge',\n",
    "                                       output_path=s3_output_location,\n",
    "                                        hyperparameters=hyperparams,\n",
    "                                        sagemaker_session=sagemaker.Session())\n",
    "\n",
    "train_channel = sagemaker.inputs.TrainingInput(\n",
    "    \"s3://{}/{}/train/\".format(bucket,prefix,train_file),\n",
    "    content_type='text/csv')\n",
    "\n",
    "validate_channel = sagemaker.inputs.TrainingInput(\n",
    "    \"s3://{}/{}/validate/\".format(bucket,prefix,validate_file),\n",
    "    content_type='text/csv')\n",
    "\n",
    "data_channels = {'train': train_channel, 'validation': validate_channel}\n",
    "\n",
    "xgb_model.fit(inputs=data_channels, logs=False)\n",
    "\n",
    "batch_X = test.iloc[:,1:];\n",
    "\n",
    "batch_X_file='batch-in.csv'\n",
    "upload_s3_csv(batch_X_file, 'batch-in', batch_X)\n",
    "\n",
    "batch_output = \"s3://{}/{}/batch-out/\".format(bucket,prefix)\n",
    "batch_input = \"s3://{}/{}/batch-in/{}\".format(bucket,prefix,batch_X_file)\n",
    "\n",
    "xgb_transformer = xgb_model.transformer(instance_count=1,\n",
    "                                       instance_type='ml.m5.2xlarge',\n",
    "                                       strategy='MultiRecord',\n",
    "                                       assemble_with='Line',\n",
    "                                       output_path=batch_output)\n",
    "\n",
    "xgb_transformer.transform(data=batch_input,\n",
    "                         data_type='S3Prefix',\n",
    "                         content_type='text/csv',\n",
    "                         split_type='Line')\n",
    "xgb_transformer.wait(logs=False)\n",
    "\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "obj = s3.get_object(Bucket=bucket, Key=f\"{prefix}/batch-out/{batch_X_file}.out\")\n",
    "results = pd.read_csv(obj['Body'], header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "I will access the file 'batch-in.csv.out' in an S3 bucket via the Boto3 library.\n",
    "Then convert the retrieved file into a Pandas DataFrame to obtain predictions for the year 2017.\n",
    "The Root Mean Squared Error (RMSE) will be computed using the actual test labels and the predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "obj = s3.get_object(Bucket=bucket, Key=\"{}/batch-out/{}\".format(prefix,'batch-in.csv.out'))\n",
    "target_predicted = pd.read_csv(io.BytesIO(obj['Body'].read()),names=[2017])\n",
    "\n",
    "test_labels = test.iloc[:, 0]\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE) for regression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Root Mean Squared Error (RMSE) calculation\n",
    "rmse = np.sqrt(mean_squared_error(test_labels, target_predicted[2017]))\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will create a scatter plot to compare how the model's predicted values align with the actual test labels for the year 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'test_labels' contains the actual test labels for regression\n",
    "# Assuming 'target_predicted' contains the predicted values for regression\n",
    "plt.scatter(test_labels, target_predicted[2017])\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Actual vs Predicted Values')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I will try to enhance the model performance by fine-tuning hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sagemaker.tuner import IntegerParameter, ContinuousParameter, HyperparameterTuner\n",
    "\n",
    "xgb = sagemaker.estimator.Estimator(container,\n",
    "                                    role=sagemaker.get_execution_role(), \n",
    "                                    instance_count=1,\n",
    "                                    instance_type='ml.m4.xlarge', \n",
    "                                    output_path='s3://{}/{}/output'.format(bucket, prefix),\n",
    "                                    sagemaker_session=sagemaker.Session())\n",
    "\n",
    "xgb.set_hyperparameters(objective='reg:squarederror',\n",
    "                        eval_metric='rmse',\n",
    "                        num_round=100)  # Adjust as needed\n",
    "\n",
    "hyperparameter_ranges = {'alpha': ContinuousParameter(0, 100),\n",
    "                         'min_child_weight': ContinuousParameter(1, 10),\n",
    "                         'subsample': ContinuousParameter(0.5, 1),\n",
    "                         'eta': ContinuousParameter(0.01, 0.3),  \n",
    "                         'num_round': IntegerParameter(1, 200)\n",
    "                        }\n",
    "\n",
    "objective_metric_name = 'validation:rmse'\n",
    "objective_type = 'Minimize'\n",
    "\n",
    "tuner = HyperparameterTuner(xgb,\n",
    "                            objective_metric_name,\n",
    "                            hyperparameter_ranges,\n",
    "                            max_jobs=10,\n",
    "                            max_parallel_jobs=1,\n",
    "                            objective_type=objective_type,\n",
    "                            early_stopping_type='Auto')\n",
    "\n",
    "tuner.fit(inputs=data_channels, include_cls_metadata=False)\n",
    "tuner.wait()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This verifies that SageMaker's most recent Hyperparameter Tuning Job is still active. It obtains status information on the job, specifically to find out if it is running, finished, or experiencing any problems. This makes it easier for you to monitor the tuning process and watch its development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.client('sagemaker').describe_hyper_parameter_tuning_job(\n",
    "    HyperParameterTuningJobName=tuner.latest_tuning_job.job_name)['HyperParameterTuningJobStatus']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code snippet gathers information from the most recent Hyperparameter Tuning Job using SageMaker Analytics. It will create a tabular view of the tuning work outcomes in order to compare and offer insights into various models. To have a better understanding of the performance of the models, particularly the top 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from sagemaker.analytics import HyperparameterTuningJobAnalytics\n",
    "\n",
    "tuner_analytics = HyperparameterTuningJobAnalytics(tuner.latest_tuning_job.name, sagemaker_session=sagemaker.Session())\n",
    "\n",
    "df_tuning_job_analytics = tuner_analytics.dataframe()\n",
    "\n",
    "# Sort the tuning job analytics by the final metrics value\n",
    "df_tuning_job_analytics.sort_values(\n",
    "    by=['FinalObjectiveValue'],\n",
    "    inplace=True,\n",
    "    ascending=False if tuner.objective_type == \"Maximize\" else True)\n",
    "\n",
    "# Show detailed analytics for the top 20 models\n",
    "df_tuning_job_analytics.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The latest tuning job is gotten here and we will indentify the best performing model for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attached_tuner = HyperparameterTuner.attach(tuner.latest_tuning_job.name, sagemaker_session=sagemaker.Session())\n",
    "best_training_job = attached_tuner.best_training_job()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best-performing model will now be loaded for further use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "algo_estimator = Estimator.attach(best_training_job)\n",
    "\n",
    "best_algo_model = algo_estimator.create_model(env={'SAGEMAKER_DEFAULT_INVOCATIONS_ACCEPT':\"text/csv\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use the best algorithm model chosen to configure an XGBoost model as a transformer. After then, this model is used to process data that has been saved in S3 for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "batch_output = \"s3://{}/{}/batch-out/\".format(bucket,prefix)\n",
    "batch_input = \"s3://{}/{}/batch-in/{}\".format(bucket,prefix,batch_X_file)\n",
    "\n",
    "xgb_transformer = best_algo_model.transformer(instance_count=1,\n",
    "                                       instance_type='ml.m4.xlarge',\n",
    "                                       strategy='MultiRecord',\n",
    "                                       assemble_with='Line',\n",
    "                                       output_path=batch_output)\n",
    "\n",
    "\n",
    "xgb_transformer.transform(data=batch_input,\n",
    "                         data_type='S3Prefix',\n",
    "                         content_type='text/csv',\n",
    "                         split_type='Line')\n",
    "xgb_transformer.wait(logs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "next I will take the prediction file \"batch-in.csv.out\" out of the S3 bucket, compare the file's predicted values with the test labels, and display the result to find the Root Mean Squared Error (RMSE) for regression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "obj = s3.get_object(Bucket=bucket, Key=\"{}/batch-out/{}\".format(prefix,'batch-in.csv.out'))\n",
    "target_predicted = pd.read_csv(io.BytesIO(obj['Body'].read()),names=[2017])\n",
    "\n",
    "test_labels = test.iloc[:, 0]\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE) for regression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Root Mean Squared Error (RMSE) calculation\n",
    "rmse = np.sqrt(mean_squared_error(test_labels, target_predicted[2017]))\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An XGBoost model that has been trained and fine-tuned will be deployed as an endpoint, and the model and endpoint configurations are then saved to an Amazon S3 bucket. The model artefacts will be downloaded to the local working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serializers import CSVSerializer\n",
    "import boto3\n",
    "\n",
    "endpoint_name = 'scikit-endpoint-21'\n",
    "predictor = tuned_xgb_model.deploy(initial_instance_count=1,\n",
    "                                   instance_type='ml.m4.xlarge',\n",
    "                                   endpoint_name=endpoint_name,\n",
    "                                   serializer=CSVSerializer())  # Serializer depends on the data format\n",
    "\n",
    "# Save the endpoint configuration to S3\n",
    "predictor.save('s3://your-bucket/endpoint-config/')  # Save the endpoint configuration in S3\n",
    "\n",
    "# Define the S3 bucket and prefix where the model artifacts are saved\n",
    "s3_bucket = 'scikit-bucket'\n",
    "s3_prefix = 'scikit-prx'\n",
    "\n",
    "# Save the model\n",
    "model_name = 'scikit-model-21'\n",
    "tuned_xgb_model.model_data = f's3://{s3_bucket}/{s3_prefix}/model.tar.gz'  # Path where the model artifacts are stored\n",
    "\n",
    "# Save model metadata in S3\n",
    "tuned_xgb_model.name = model_name\n",
    "tuned_xgb_model.create_model()\n",
    "tuned_xgb_model.save(f's3://{s3_bucket}/{s3_prefix}/model-config/')  # Save model metadata in S3\n",
    "\n",
    "# Download the model artifact to the local working directory\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Replace 'your-bucket' and 'your-prefix' with the bucket and prefix where your model artifacts are stored\n",
    "local_model_path = 'local-model/model.tar.gz'\n",
    "s3.download_file(s3_bucket, f'{s3_prefix}/model.tar.gz', local_model_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
