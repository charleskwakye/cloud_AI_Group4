{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\teste\\documents\\3rd year\\cloud ai\\cloud ai github\\cloudai\\venv\\lib\\site-packages (1.3.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in c:\\users\\teste\\documents\\3rd year\\cloud ai\\cloud ai github\\cloudai\\venv\\lib\\site-packages (from scikit-learn) (1.26.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\teste\\documents\\3rd year\\cloud ai\\cloud ai github\\cloudai\\venv\\lib\\site-packages (from scikit-learn) (1.11.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\teste\\documents\\3rd year\\cloud ai\\cloud ai github\\cloudai\\venv\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\teste\\documents\\3rd year\\cloud ai\\cloud ai github\\cloudai\\venv\\lib\\site-packages (from scikit-learn) (3.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "import warnings, requests, zipfile, io\n",
    "warnings.simplefilter('ignore')\n",
    "import pandas as pd\n",
    "from scipy.io import arff\n",
    "\n",
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.image_uris import retrieve\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def plot_roc(test_labels, target_predicted_binary):\n",
    "    TN, FP, FN, TP = confusion_matrix(test_labels, target_predicted_binary).ravel()\n",
    "    # Sensitivity, hit rate, recall, or true positive rate\n",
    "    Sensitivity  = float(TP)/(TP+FN)*100\n",
    "    # Specificity or true negative rate\n",
    "    Specificity  = float(TN)/(TN+FP)*100\n",
    "    # Precision or positive predictive value\n",
    "    Precision = float(TP)/(TP+FP)*100\n",
    "    # Negative predictive value\n",
    "    NPV = float(TN)/(TN+FN)*100\n",
    "    # Fall out or false positive rate\n",
    "    FPR = float(FP)/(FP+TN)*100\n",
    "    # False negative rate\n",
    "    FNR = float(FN)/(TP+FN)*100\n",
    "    # False discovery rate\n",
    "    FDR = float(FP)/(TP+FP)*100\n",
    "    # Overall accuracy\n",
    "    ACC = float(TP+TN)/(TP+FP+FN+TN)*100\n",
    "\n",
    "    print(f\"Sensitivity or TPR: {Sensitivity}%\")    \n",
    "    print(f\"Specificity or TNR: {Specificity}%\") \n",
    "    print(f\"Precision: {Precision}%\")   \n",
    "    print(f\"Negative Predictive Value: {NPV}%\")  \n",
    "    print( f\"False Positive Rate: {FPR}%\") \n",
    "    print(f\"False Negative Rate: {FNR}%\")  \n",
    "    print(f\"False Discovery Rate: {FDR}%\" )\n",
    "    print(f\"Accuracy: {ACC}%\") \n",
    "\n",
    "    test_labels = test.iloc[:,0];\n",
    "    print(\"Validation AUC\", roc_auc_score(test_labels, target_predicted_binary) )\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(test_labels, target_predicted_binary)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % (roc_auc))\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "\n",
    "    # create the axis of thresholds (scores)\n",
    "    ax2 = plt.gca().twinx()\n",
    "    ax2.plot(fpr, thresholds, markeredgecolor='r',linestyle='dashed', color='r')\n",
    "    ax2.set_ylabel('Threshold',color='r')\n",
    "    ax2.set_ylim([thresholds[-1],thresholds[0]])\n",
    "    ax2.set_xlim([fpr[0],fpr[-1]])\n",
    "\n",
    "    print(plt.figure())\n",
    "\n",
    "def plot_confusion_matrix(test_labels, target_predicted):\n",
    "    matrix = confusion_matrix(test_labels, target_predicted)\n",
    "    df_confusion = pd.DataFrame(matrix)\n",
    "    colormap = sns.color_palette(\"BrBG\", 10)\n",
    "    sns.heatmap(df_confusion, annot=True, fmt='.2f', cbar=None, cmap=colormap)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel(\"True Class\")\n",
    "    plt.xlabel(\"Predicted Class\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "df = pd.read_csv('cropfolder/cropStats.csv',delimiter=',')\n",
    "\n",
    "# Dropping the first and last columns\n",
    "df = df.iloc[:, 1:-1]  # Selects all rows, and columns from index 1 to the second-to-last column\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df['states_encoded'] = label_encoder.fit_transform(df['Location'])\n",
    "\n",
    "# Create a new DataFrame with 'states_encoded' as the first column\n",
    "new_order = ['states_encoded'] + [col for col in df if col != 'states_encoded']\n",
    "df = df[new_order]\n",
    "\n",
    "# Drop the original 'Location' column after encoding\n",
    "df = df.drop('Location', axis=1)\n",
    "df\n",
    "\n",
    "# column to be predicted is 2017 column, so that comes first\n",
    "\n",
    "cols = df.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "df = df[cols]\n",
    "df\n",
    "\n",
    "train, test_and_validate = train_test_split(df, test_size=0.2, random_state=42)\n",
    "test, validate = train_test_split(test_and_validate, test_size=0.5, random_state=42)\n",
    "\n",
    "prefix='lab3'\n",
    "\n",
    "train_file='crop_train.csv'\n",
    "test_file='crop_test.csv'\n",
    "validate_file='crop_validate.csv'\n",
    "\n",
    "s3_resource = boto3.Session().resource('s3')\n",
    "def upload_s3_csv(filename, folder, dataframe):\n",
    "    csv_buffer = io.StringIO()\n",
    "    dataframe.to_csv(csv_buffer, header=False, index=False )\n",
    "    s3_resource.Bucket(bucket).Object(os.path.join(prefix, folder, filename)).put(Body=csv_buffer.getvalue())\n",
    "\n",
    "upload_s3_csv(train_file, 'train', train)\n",
    "upload_s3_csv(test_file, 'test', test)\n",
    "upload_s3_csv(validate_file, 'validate', validate)\n",
    "\n",
    "container = retrieve('xgboost',boto3.Session().region_name,'1.0-1')\n",
    "\n",
    "hyperparams = {\n",
    "    \"num_round\": \"100\",\n",
    "    \"eval_metric\": \"rmse\",  # Evaluation metric (Root Mean Squared Error)\n",
    "    \"objective\": \"reg:squarederror\",  # Objective for regression\n",
    "    \"silent\": 1\n",
    "}\n",
    "\n",
    "s3_output_location=\"s3://{}/{}/output/\".format(bucket,prefix)\n",
    "xgb_model=sagemaker.estimator.Estimator(container,\n",
    "                                       sagemaker.get_execution_role(),\n",
    "                                       instance_count=1,\n",
    "                                       instance_type='ml.m5.2xlarge',\n",
    "                                       output_path=s3_output_location,\n",
    "                                        hyperparameters=hyperparams,\n",
    "                                        sagemaker_session=sagemaker.Session())\n",
    "\n",
    "train_channel = sagemaker.inputs.TrainingInput(\n",
    "    \"s3://{}/{}/train/\".format(bucket,prefix,train_file),\n",
    "    content_type='text/csv')\n",
    "\n",
    "validate_channel = sagemaker.inputs.TrainingInput(\n",
    "    \"s3://{}/{}/validate/\".format(bucket,prefix,validate_file),\n",
    "    content_type='text/csv')\n",
    "\n",
    "data_channels = {'train': train_channel, 'validation': validate_channel}\n",
    "\n",
    "xgb_model.fit(inputs=data_channels, logs=False)\n",
    "\n",
    "batch_X = test.iloc[:,1:];\n",
    "\n",
    "batch_X_file='batch-in.csv'\n",
    "upload_s3_csv(batch_X_file, 'batch-in', batch_X)\n",
    "\n",
    "batch_output = \"s3://{}/{}/batch-out/\".format(bucket,prefix)\n",
    "batch_input = \"s3://{}/{}/batch-in/{}\".format(bucket,prefix,batch_X_file)\n",
    "\n",
    "xgb_transformer = xgb_model.transformer(instance_count=1,\n",
    "                                       instance_type='ml.m5.2xlarge',\n",
    "                                       strategy='MultiRecord',\n",
    "                                       assemble_with='Line',\n",
    "                                       output_path=batch_output)\n",
    "\n",
    "xgb_transformer.transform(data=batch_input,\n",
    "                         data_type='S3Prefix',\n",
    "                         content_type='text/csv',\n",
    "                         split_type='Line')\n",
    "xgb_transformer.wait(logs=False)\n",
    "\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "obj = s3.get_object(Bucket=bucket, Key=f\"{prefix}/batch-out/{batch_X_file}.out\")\n",
    "results = pd.read_csv(obj['Body'], header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "obj = s3.get_object(Bucket=bucket, Key=\"{}/batch-out/{}\".format(prefix,'batch-in.csv.out'))\n",
    "target_predicted = pd.read_csv(io.BytesIO(obj['Body'].read()),names=[2017])\n",
    "\n",
    "test_labels = test.iloc[:, 0]\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE) for regression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Root Mean Squared Error (RMSE) calculation\n",
    "rmse = np.sqrt(mean_squared_error(test_labels, target_predicted[2017]))\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'test_labels' contains the actual test labels for regression\n",
    "# Assuming 'target_predicted' contains the predicted values for regression\n",
    "plt.scatter(test_labels, target_predicted[2017])\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Actual vs Predicted Values')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sagemaker.tuner import IntegerParameter, ContinuousParameter, HyperparameterTuner\n",
    "\n",
    "xgb = sagemaker.estimator.Estimator(container,\n",
    "                                    role=sagemaker.get_execution_role(), \n",
    "                                    instance_count=1,\n",
    "                                    instance_type='ml.m4.xlarge', \n",
    "                                    output_path='s3://{}/{}/output'.format(bucket, prefix),\n",
    "                                    sagemaker_session=sagemaker.Session())\n",
    "\n",
    "xgb.set_hyperparameters(objective='reg:squarederror',\n",
    "                        eval_metric='rmse',\n",
    "                        num_round=100)  # Adjust as needed\n",
    "\n",
    "hyperparameter_ranges = {'alpha': ContinuousParameter(0, 100),\n",
    "                         'min_child_weight': ContinuousParameter(1, 10),\n",
    "                         'subsample': ContinuousParameter(0.5, 1),\n",
    "                         'eta': ContinuousParameter(0.01, 0.3),  \n",
    "                         'num_round': IntegerParameter(1, 200)\n",
    "                        }\n",
    "\n",
    "objective_metric_name = 'validation:rmse'\n",
    "objective_type = 'Minimize'\n",
    "\n",
    "tuner = HyperparameterTuner(xgb,\n",
    "                            objective_metric_name,\n",
    "                            hyperparameter_ranges,\n",
    "                            max_jobs=10,\n",
    "                            max_parallel_jobs=1,\n",
    "                            objective_type=objective_type,\n",
    "                            early_stopping_type='Auto')\n",
    "\n",
    "tuner.fit(inputs=data_channels, include_cls_metadata=False)\n",
    "tuner.wait()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.client('sagemaker').describe_hyper_parameter_tuning_job(\n",
    "    HyperParameterTuningJobName=tuner.latest_tuning_job.job_name)['HyperParameterTuningJobStatus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from sagemaker.analytics import HyperparameterTuningJobAnalytics\n",
    "\n",
    "tuner_analytics = HyperparameterTuningJobAnalytics(tuner.latest_tuning_job.name, sagemaker_session=sagemaker.Session())\n",
    "\n",
    "df_tuning_job_analytics = tuner_analytics.dataframe()\n",
    "\n",
    "# Sort the tuning job analytics by the final metrics value\n",
    "df_tuning_job_analytics.sort_values(\n",
    "    by=['FinalObjectiveValue'],\n",
    "    inplace=True,\n",
    "    ascending=False if tuner.objective_type == \"Maximize\" else True)\n",
    "\n",
    "# Show detailed analytics for the top 20 models\n",
    "df_tuning_job_analytics.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attached_tuner = HyperparameterTuner.attach(tuner.latest_tuning_job.name, sagemaker_session=sagemaker.Session())\n",
    "best_training_job = attached_tuner.best_training_job()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "algo_estimator = Estimator.attach(best_training_job)\n",
    "\n",
    "best_algo_model = algo_estimator.create_model(env={'SAGEMAKER_DEFAULT_INVOCATIONS_ACCEPT':\"text/csv\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "batch_output = \"s3://{}/{}/batch-out/\".format(bucket,prefix)\n",
    "batch_input = \"s3://{}/{}/batch-in/{}\".format(bucket,prefix,batch_X_file)\n",
    "\n",
    "xgb_transformer = best_algo_model.transformer(instance_count=1,\n",
    "                                       instance_type='ml.m4.xlarge',\n",
    "                                       strategy='MultiRecord',\n",
    "                                       assemble_with='Line',\n",
    "                                       output_path=batch_output)\n",
    "\n",
    "\n",
    "xgb_transformer.transform(data=batch_input,\n",
    "                         data_type='S3Prefix',\n",
    "                         content_type='text/csv',\n",
    "                         split_type='Line')\n",
    "xgb_transformer.wait(logs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "obj = s3.get_object(Bucket=bucket, Key=\"{}/batch-out/{}\".format(prefix,'batch-in.csv.out'))\n",
    "target_predicted = pd.read_csv(io.BytesIO(obj['Body'].read()),names=[2017])\n",
    "\n",
    "test_labels = test.iloc[:, 0]\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE) for regression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Root Mean Squared Error (RMSE) calculation\n",
    "rmse = np.sqrt(mean_squared_error(test_labels, target_predicted[2017]))\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serializers import CSVSerializer\n",
    "import boto3\n",
    "\n",
    "# Assuming you have trained and tuned your model (let's assume it's named 'tuned_xgb_model')\n",
    "# Deploy the model as an endpoint\n",
    "endpoint_name = 'scikit-endpoint-21'\n",
    "predictor = tuned_xgb_model.deploy(initial_instance_count=1,\n",
    "                                   instance_type='ml.m4.xlarge',\n",
    "                                   endpoint_name=endpoint_name,\n",
    "                                   serializer=CSVSerializer())  # Serializer depends on the data format\n",
    "\n",
    "# Save the endpoint configuration to S3\n",
    "predictor.save('s3://your-bucket/endpoint-config/')  # Save the endpoint configuration in S3\n",
    "\n",
    "# Define the S3 bucket and prefix where the model artifacts are saved\n",
    "s3_bucket = 'scikit-bucket'\n",
    "s3_prefix = 'scikit-prx'\n",
    "\n",
    "# Save the model\n",
    "model_name = 'scikit-model-21'\n",
    "tuned_xgb_model.model_data = f's3://{s3_bucket}/{s3_prefix}/model.tar.gz'  # Path where the model artifacts are stored\n",
    "\n",
    "# Save model metadata in S3\n",
    "tuned_xgb_model.name = model_name\n",
    "tuned_xgb_model.create_model()\n",
    "tuned_xgb_model.save(f's3://{s3_bucket}/{s3_prefix}/model-config/')  # Save model metadata in S3\n",
    "\n",
    "# Download the model artifact to the local working directory\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Replace 'your-bucket' and 'your-prefix' with the bucket and prefix where your model artifacts are stored\n",
    "local_model_path = 'local-model/model.tar.gz'\n",
    "s3.download_file(s3_bucket, f'{s3_prefix}/model.tar.gz', local_model_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
